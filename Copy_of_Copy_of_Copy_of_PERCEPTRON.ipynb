{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjana2011/gym-webpage/blob/main/Copy_of_Copy_of_Copy_of_PERCEPTRON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IC9aOQM8iJC"
      },
      "source": [
        "# Perceptron Learning Algorithm Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh7M0_uYa5Ie",
        "outputId": "3c13591f-1dd2-4787-d76e-992021ca4498"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ib3aJqdEbPC2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZB46BXQ8iJI"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us first understand what np.zeros(2+1) do before implementing Perceptron model"
      ],
      "metadata": {
        "id": "B3RcDFDjKUVt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyuHnNrR8iJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1360e753-731c-46ed-f754-d4965fb1cb78"
      },
      "source": [
        "W = np.zeros(2+1)\n",
        "W"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " np.insert(X, 0, 1) is used for horizontal stacking of 1's in 0th column\n"
      ],
      "metadata": {
        "id": "pwwJ1O1EKlBn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szwQn6Yd8iJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a82e3b-8512-4aa8-d266-f72a41d212ba"
      },
      "source": [
        "X=[2,3]\n",
        "np.insert(X, 0, 1)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtpJjmC9N8sp"
      },
      "source": [
        "Understand each code step by step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWdHQsjd8iJh"
      },
      "source": [
        "# initialization code\n",
        "def __init__(self, input_size, lr=5, epochs=2, bias=1):\n",
        "    self.W = np.zeros(input_size+bias)\n",
        "    self.epochs = epochs\n",
        "    self.lr = lr"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fom45Tzh8iJn"
      },
      "source": [
        "# Activation function code which is a simple step function\n",
        "def activation_fn(self, x):\n",
        "        #return (x >= 0).astype(np.float32)\n",
        "        return 1 if x >= 0 else 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix_xNDhi8iJs"
      },
      "source": [
        "# Calculating dot product of W and X (input vector) and applying step function\n",
        "def predict(self, x):\n",
        "        z = self.W.T.dot(x)\n",
        "        a = self.activation_fn(z)\n",
        "        return a"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvRpXqxd8iJz"
      },
      "source": [
        "# Perceptron Learning code running all the samples for given epochs or iterations\n",
        "def fit(self, X, OutputLabel):\n",
        "    no_of_smaples=4\n",
        "    for _ in range(self.epochs):\n",
        "        for i in range(no_of_samples):\n",
        "            y = self.predict(X[i])\n",
        "            e = OutputLabel[i] - y\n",
        "            self.W = self.W + self.lr * e * np.insert(X[i], 0, 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6zeqwrM8iJ6"
      },
      "source": [
        "# The complete executable code of Perceptron model  in one step "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90IArkfa8iJ8"
      },
      "source": [
        " \n",
        "class Perceptron(object):\n",
        "    \"\"\"Implements a perceptron network\"\"\"\n",
        "    def __init__(self, input_size, lr=5, epochs=5):\n",
        "        self.W = np.zeros(input_size+1)\n",
        "        # add one for bias\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "        self.loss_lst = []\n",
        "    \n",
        "    def activation_fn(self, x):\n",
        "        #return (x >= 0).astype(np.float32)\n",
        "        return 1 if x >= 0 else 0\n",
        " \n",
        "    def predict(self, x):\n",
        "        z = self.W.T.dot(x)\n",
        "        a = self.activation_fn(z)\n",
        "        return a\n",
        " \n",
        "    def fit(self, X, d):\n",
        "        for _ in range(self.epochs):\n",
        "            for i in range(d.shape[0]):\n",
        "                x = np.insert(X[i], 0, 1)\n",
        "                y = self.predict(x)\n",
        "                e = d[i] - y\n",
        "                self.W = self.W + self.lr * e * x\n",
        "            self.loss_lst.append(e)                  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxkfR3Rr8iKC"
      },
      "source": [
        "# AND GATE EXAMPLE WITH NO OF SAMPLES/RECORDS AS 4 AND EPOCHS AS 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FkER4a68iKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8710380b-59c3-4064-ca71-5f0932abbbad"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    X = np.array([\n",
        "        [0, 0],\n",
        "        [0, 1],\n",
        "        [1, 0],\n",
        "        [1, 1]\n",
        "    ])\n",
        "    d = np.array([1, 0, 0, 1])\n",
        " \n",
        "    perceptron = Perceptron(input_size=2)\n",
        "    perceptron.fit(X, d)\n",
        "    print(perceptron.W)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-5.  5.  0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "gckUX4MnQ3ho",
        "outputId": "2c230de1-c233-4e42-9ec9-95bdcefd0790"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x_axis = [int(x) for x in range(5)]\n",
        "y_axis = perceptron.loss_lst\n",
        "plt.plot(x_axis, y_axis)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks5fWOcq8iKN"
      },
      "source": [
        "# Using the AND gate data, we should get a weight vector of [-3, 2, 1]. This means that the bias is -3 and the weights are 2 and 1 for x_1 and x_2, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWfEutm18iKP"
      },
      "source": [
        "# LETS TEST MANUALLY\n",
        "# let us test for x=[0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Zw-a2-8iKR",
        "outputId": "2deab235-4a3a-4dec-fa50-018f7971681c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x=[1, 0, 1]\n",
        "y= -3*1+2*0+1*1\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb3JLCbk8iKW"
      },
      "source": [
        "# since it is a negative value on applying activation function we get zero which is correct"
      ]
    }
  ]
}